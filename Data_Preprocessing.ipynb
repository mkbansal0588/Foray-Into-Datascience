{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drwxr-xr-x@ 211 mohit.k.bansal  staff        6752 Dec 11 12:30 101CANON\n",
      "drwxr-xr-x@  21 mohit.k.bansal  staff         672 Jun 27 22:49 Accenture\n",
      "drwxr-xr-x   26 mohit.k.bansal  staff         832 Nov 11 20:59 Australia\n",
      "drwxr-xr-x   11 mohit.k.bansal  staff         352 Feb 28  2019 BirthCertificateDocuments\n",
      "drwxr-xr-x    3 mohit.k.bansal  staff          96 Feb 19  2019 Coursera\n",
      "drwxr-xr-x@  14 mohit.k.bansal  staff         448 Nov  1  2017 Machine Learning A-Z Template Folder\n",
      "drwxr-xr-x   10 mohit.k.bansal  staff         320 Oct 10 08:52 Mohit Visa Stamping docs\n",
      "drwx------@  39 mohit.k.bansal  staff        1248 May 15  2019 Mohit_Degree_Documents\n",
      "drwxr-xr-x   15 mohit.k.bansal  staff         480 Oct 22 16:36 NUPUR-RFE-Documents\n",
      "drwxr-xr-x@  26 mohit.k.bansal  staff         832 Sep 16 17:14 Need to mail\n",
      "drwxr-xr-x   61 mohit.k.bansal  staff        1952 Nov 11 20:58 Nupur_Extension_Documents_Verified\n",
      "drwxr-xr-x   10 mohit.k.bansal  staff         320 Feb 28  2019 PoliceClearanceCertificate\n",
      "drwxr-xr-x    9 mohit.k.bansal  staff         288 Nov 11 21:02 Tax_Documents\n",
      "drwxr-xr-x   13 mohit.k.bansal  staff         416 Sep 18 11:02 Visa Stamping\n",
      "drwxr-xr-x    7 mohit.k.bansal  staff         224 Oct 22 16:17 nupur RFE\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "ls -l /Users/mohit.k.bansal/Downloads/ | egrep ^d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 0\n",
      "drwxr-xr-x@  4 mohit.k.bansal  staff  128 Nov  1  2017 Part 0 - Welcome to Machine Learning A-Z\n",
      "drwxr-xr-x@  4 mohit.k.bansal  staff  128 Nov  1  2017 Part 1 - Data Preprocessing\n",
      "drwxr-xr-x@  6 mohit.k.bansal  staff  192 Mar 10  2017 Part 10 - Model Selection & Boosting\n",
      "drwxr-xr-x@ 12 mohit.k.bansal  staff  384 Mar 10  2017 Part 2 - Regression\n",
      "drwxr-xr-x@ 12 mohit.k.bansal  staff  384 Mar 10  2017 Part 3 - Classification\n",
      "drwxr-xr-x@  6 mohit.k.bansal  staff  192 Mar 10  2017 Part 4 - Clustering\n",
      "drwxr-xr-x@  6 mohit.k.bansal  staff  192 Mar 10  2017 Part 5 - Association Rule Learning\n",
      "drwxr-xr-x@  6 mohit.k.bansal  staff  192 Mar 10  2017 Part 6 - Reinforcement Learning\n",
      "drwxr-xr-x@  5 mohit.k.bansal  staff  160 Mar 10  2017 Part 7 - Natural Language Processing\n",
      "drwxr-xr-x@  6 mohit.k.bansal  staff  192 Mar 10  2017 Part 8 - Deep Learning\n",
      "drwxr-xr-x@  7 mohit.k.bansal  staff  224 Mar 10  2017 Part 9 - Dimensionality Reduction\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ls -l /Users/mohit.k.bansal/Downloads/Machine\\ Learning\\ A-Z\\ Template\\ Folder/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%bash\n",
    "#ls -l '/Users/mohit.k.bansal/Downloads/Machine Learning A-Z Template Folder/Part 1 - Data Preprocessing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/Users/mohit.k.bansal/Downloads/Machine Learning A-Z Template Folder/Part 1 - Data Preprocessing/Section 2 -------------------- Part 1 - Data Preprocessing --------------------/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>38.777778</td>\n",
       "      <td>63777.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>7.693793</td>\n",
       "      <td>12265.579662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>48000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>54000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>61000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>72000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>83000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Age        Salary\n",
       "count   9.000000      9.000000\n",
       "mean   38.777778  63777.777778\n",
       "std     7.693793  12265.579662\n",
       "min    27.000000  48000.000000\n",
       "25%    35.000000  54000.000000\n",
       "50%    38.000000  61000.000000\n",
       "75%    44.000000  72000.000000\n",
       "max    50.000000  83000.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 4 columns):\n",
      "Country      10 non-null object\n",
      "Age          9 non-null float64\n",
      "Salary       9 non-null float64\n",
      "Purchased    10 non-null object\n",
      "dtypes: float64(2), object(2)\n",
      "memory usage: 448.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>France</td>\n",
       "      <td>44.0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Spain</td>\n",
       "      <td>27.0</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Germany</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Spain</td>\n",
       "      <td>38.0</td>\n",
       "      <td>61000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Germany</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>France</td>\n",
       "      <td>35.0</td>\n",
       "      <td>58000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Spain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>France</td>\n",
       "      <td>48.0</td>\n",
       "      <td>79000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Germany</td>\n",
       "      <td>50.0</td>\n",
       "      <td>83000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>France</td>\n",
       "      <td>37.0</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country   Age   Salary Purchased\n",
       "0   France  44.0  72000.0        No\n",
       "1    Spain  27.0  48000.0       Yes\n",
       "2  Germany  30.0  54000.0        No\n",
       "3    Spain  38.0  61000.0        No\n",
       "4  Germany  40.0      NaN       Yes\n",
       "5   France  35.0  58000.0       Yes\n",
       "6    Spain   NaN  52000.0        No\n",
       "7   France  48.0  79000.0       Yes\n",
       "8  Germany  50.0  83000.0        No\n",
       "9   France  37.0  67000.0       Yes"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38.77777777777778"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Age'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.fillna(data.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>France</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>72000.000000</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Spain</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>48000.000000</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Germany</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>54000.000000</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Spain</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>61000.000000</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Germany</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>63777.777778</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>France</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>58000.000000</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Spain</td>\n",
       "      <td>38.777778</td>\n",
       "      <td>52000.000000</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>France</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>79000.000000</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Germany</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>83000.000000</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>France</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>67000.000000</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country        Age        Salary Purchased\n",
       "0   France  44.000000  72000.000000        No\n",
       "1    Spain  27.000000  48000.000000       Yes\n",
       "2  Germany  30.000000  54000.000000        No\n",
       "3    Spain  38.000000  61000.000000        No\n",
       "4  Germany  40.000000  63777.777778       Yes\n",
       "5   France  35.000000  58000.000000       Yes\n",
       "6    Spain  38.777778  52000.000000        No\n",
       "7   France  48.000000  79000.000000       Yes\n",
       "8  Germany  50.000000  83000.000000        No\n",
       "9   France  37.000000  67000.000000       Yes"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/Users/mohit.k.bansal/Downloads/Machine Learning A-Z Template Folder/Part 1 - Data Preprocessing/Section 2 -------------------- Part 1 - Data Preprocessing --------------------/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>France</td>\n",
       "      <td>44.0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Spain</td>\n",
       "      <td>27.0</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Germany</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Spain</td>\n",
       "      <td>38.0</td>\n",
       "      <td>61000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Germany</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>France</td>\n",
       "      <td>35.0</td>\n",
       "      <td>58000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Spain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>France</td>\n",
       "      <td>48.0</td>\n",
       "      <td>79000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Germany</td>\n",
       "      <td>50.0</td>\n",
       "      <td>83000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>France</td>\n",
       "      <td>37.0</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country   Age   Salary Purchased\n",
       "0   France  44.0  72000.0        No\n",
       "1    Spain  27.0  48000.0       Yes\n",
       "2  Germany  30.0  54000.0        No\n",
       "3    Spain  38.0  61000.0        No\n",
       "4  Germany  40.0      NaN       Yes\n",
       "5   France  35.0  58000.0       Yes\n",
       "6    Spain   NaN  52000.0        No\n",
       "7   France  48.0  79000.0       Yes\n",
       "8  Germany  50.0  83000.0        No\n",
       "9   France  37.0  67000.0       Yes"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.iloc[:,0:3].values\n",
    "Y=data.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['France', 44.0, 72000.0],\n",
       "       ['Spain', 27.0, 48000.0],\n",
       "       ['Germany', 30.0, 54000.0],\n",
       "       ['Spain', 38.0, 61000.0],\n",
       "       ['Germany', 40.0, 63777.77777777778],\n",
       "       ['France', 35.0, 58000.0],\n",
       "       ['Spain', 38.77777777777778, 52000.0],\n",
       "       ['France', 48.0, 79000.0],\n",
       "       ['Germany', 50.0, 83000.0],\n",
       "       ['France', 37.0, 67000.0]], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:66: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "imputer = Imputer(missing_values = 'NaN', strategy = 'mean', axis = 0)\n",
    "imputer = imputer.fit(X[:,1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:,1:3] = imputer.transform(X[:,1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['France', 44.0, 72000.0],\n",
       "       ['Spain', 27.0, 48000.0],\n",
       "       ['Germany', 30.0, 54000.0],\n",
       "       ['Spain', 38.0, 61000.0],\n",
       "       ['Germany', 40.0, 63777.77777777778],\n",
       "       ['France', 35.0, 58000.0],\n",
       "       ['Spain', 38.77777777777778, 52000.0],\n",
       "       ['France', 48.0, 79000.0],\n",
       "       ['Germany', 50.0, 83000.0],\n",
       "       ['France', 37.0, 67000.0]], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder_X = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:,0] = labelencoder_X.fit_transform(X[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 44.0, 72000.0],\n",
       "       [2, 27.0, 48000.0],\n",
       "       [1, 30.0, 54000.0],\n",
       "       [2, 38.0, 61000.0],\n",
       "       [1, 40.0, 63777.77777777778],\n",
       "       [0, 35.0, 58000.0],\n",
       "       [2, 38.77777777777778, 52000.0],\n",
       "       [0, 48.0, 79000.0],\n",
       "       [1, 50.0, 83000.0],\n",
       "       [0, 37.0, 67000.0]], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehotencoder_X = OneHotEncoder(categorical_features=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "X = onehotencoder_X.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        4.40000000e+01, 7.20000000e+04],\n",
       "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        2.70000000e+01, 4.80000000e+04],\n",
       "       [1.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n",
       "        3.00000000e+01, 5.40000000e+04],\n",
       "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        3.80000000e+01, 6.10000000e+04],\n",
       "       [1.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n",
       "        4.00000000e+01, 6.37777778e+04],\n",
       "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        3.50000000e+01, 5.80000000e+04],\n",
       "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        3.87777778e+01, 5.20000000e+04],\n",
       "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        4.80000000e+01, 7.90000000e+04],\n",
       "       [1.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n",
       "        5.00000000e+01, 8.30000000e+04],\n",
       "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        3.70000000e+01, 6.70000000e+04]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder_y = LabelEncoder()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = labelencoder_y.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 1, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as tts\n",
    "X_train, X_test, y_train, y_test = tts(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n",
       "        4.00000000e+01, 6.37777778e+04],\n",
       "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        3.70000000e+01, 6.70000000e+04],\n",
       "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        2.70000000e+01, 4.80000000e+04],\n",
       "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        3.87777778e+01, 5.20000000e+04],\n",
       "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        4.80000000e+01, 7.90000000e+04],\n",
       "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        3.80000000e+01, 6.10000000e+04],\n",
       "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        4.40000000e+01, 7.20000000e+04],\n",
       "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        3.50000000e+01, 5.80000000e+04]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country      Spain\n",
       "Age             27\n",
       "Salary       48000\n",
       "Purchased      Yes\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = data.iloc[1,:]\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data1.append(data.iloc[8,:].values)\n",
    "data1 = data1.append(data.iloc[8,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country        Spain\n",
       "Age               27\n",
       "Salary         48000\n",
       "Purchased        Yes\n",
       "Country      Germany\n",
       "Age               50\n",
       "Salary         83000\n",
       "Purchased         No\n",
       "dtype: object"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1a31df1950>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAUJUlEQVR4nO3df4xd5Z3f8fenNmYdlNSGDAhsUryp5ZSsFAO3hG2kSIFdbNMqdiQiGW2FFSE5jWDb7R8U/BdpQqVSGrGLlCCRQGJ2kxjWgmClBMci7H8JMI5dwBDLEyBgm4VBxtl0YwF2vv3jPpO9OzP23PGPGQ/zfklH95zveZ4zzzk68mfuc8/1pKqQJM1u/2K6ByBJmn6GgSTJMJAkGQaSJAwDSRIwd7oHcLw+/OEP10UXXTTdw5CkGWX79u1vVdXA6PqMDYOLLrqIwcHB6R6GJM0oSX41Xt1pIkmSYSBJMgwkSRgGkiQMA0kSM/hpIkmaTX6wYx93bt3N/oOHuGDBfG5esYw1lyw6acc3DCTpNPeDHfvY8PBzHHrvCAD7Dh5iw8PPAZy0QHCaSJJOc3du3f37IBhx6L0j3Ll190n7GYaBJJ3m9h88NKn68TAMJOk0d8GC+ZOqHw/DQJJOczevWMb8M+b8s9r8M+Zw84plJ+1n+AGyJJ3mRj4k9mkiSZrl1lyy6KT+4z+a00SSJMNAkmQYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgSaLPMEjyX5PsSvJ8ku8n+YMkS5I8lWRPkgeTzGttz2zbQ23/RT3H2dDqu5Os6KmvbLWhJLee7JOUJB3bhGGQZBHwn4FOVf0RMAdYC9wB3FVVS4G3gRtalxuAt6vqXwN3tXYkubj1+ziwEvhGkjlJ5gBfB1YBFwPXtbaSpCnS7zTRXGB+krnAB4DXgSuBzW3/RmBNW1/dtmn7r0qSVt9UVe9U1cvAEHB5W4aq6qWqehfY1NpKkqbIhGFQVfuA/w28SjcEfg1sBw5W1eHWbC8w8j8oLQJea30Pt/bn9NZH9TlafYwk65MMJhkcHh7u5/wkSX3oZ5poId3f1JcAFwBn0Z3SGa1Guhxl32TrY4tV91ZVp6o6AwMDEw1dktSnfqaJ/gR4uaqGq+o94GHg3wEL2rQRwGJgf1vfC1wI0Pb/S+BAb31Un6PVJUlTpJ8weBW4IskH2tz/VcALwJPAta3NOuDRtr6lbdP2/6SqqtXXtqeNlgBLgaeBZ4Cl7emkeXQ/ZN5y4qcmSerXhH/cpqqeSrIZ+DlwGNgB3Av8H2BTkttb7b7W5T7gr5MM0X1HsLYdZ1eSh+gGyWHgxqo6ApDkJmAr3SeV7q+qXSfvFCVJE0n3l/aZp9Pp1ODg4HQPQ5JmlCTbq6ozuu43kCVJhoEkyTCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAk0UcYJFmWZGfP8g9J/iLJl5Ps66lf09NnQ5KhJLuTrOipr2y1oSS39tSXJHkqyZ4kDyaZd/JPVZJ0NBOGQVXtrqrlVbUcuAz4LfBI233XyL6qegwgycXAWuDjwErgG0nmJJkDfB1YBVwMXNfaAtzRjrUUeBu44eSdoiRpIpOdJroK+GVV/eoYbVYDm6rqnap6GRgCLm/LUFW9VFXvApuA1UkCXAlsbv03AmsmOS5J0gmYbBisBb7fs31TkmeT3J9kYastAl7rabO31Y5WPwc4WFWHR9XHSLI+yWCSweHh4UkOXZJ0NH2HQZvH/yzwt610D/BRYDnwOvC1kabjdK/jqI8tVt1bVZ2q6gwMDPQ7dEnSBOZOou0q4OdV9QbAyCtAkm8CP2ybe4ELe/otBva39fHqbwELksxt7w5620uSpsBkpomuo2eKKMn5Pfs+Bzzf1rcAa5OcmWQJsBR4GngGWNqeHJpHd8ppS1UV8CRwbeu/Dnj0eE5GknR8+npnkOQDwJ8CX+wp/68ky+lO6bwysq+qdiV5CHgBOAzcWFVH2nFuArYCc4D7q2pXO9YtwKYktwM7gPtO8LwkSZOQ7i/mM0+n06nBwcHpHoYkzShJtldVZ3TdbyBLkgwDSZJhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCTRRxgkWZZkZ8/yD0n+IsnZSbYl2dNeF7b2SXJ3kqEkzya5tOdY61r7PUnW9dQvS/Jc63N3kpya05UkjWfCMKiq3VW1vKqWA5cBvwUeAW4FnqiqpcATbRtgFbC0LeuBewCSnA3cBnwSuBy4bSRAWpv1Pf1WnpSzkyT1ZbLTRFcBv6yqXwGrgY2tvhFY09ZXAw9U18+ABUnOB1YA26rqQFW9DWwDVrZ9H6qqn1ZVAQ/0HEuSNAUmGwZrge+39fOq6nWA9npuqy8CXuvps7fVjlXfO059jCTrkwwmGRweHp7k0CVJR9N3GCSZB3wW+NuJmo5Tq+Oojy1W3VtVnarqDAwMTDAMSVK/JvPOYBXw86p6o22/0aZ4aK9vtvpe4MKefouB/RPUF49TlyRNkcmEwXX80xQRwBZg5ImgdcCjPfXr21NFVwC/btNIW4GrkyxsHxxfDWxt+36T5Ir2FNH1PceSJE2Buf00SvIB4E+BL/aU/yfwUJIbgFeBz7f6Y8A1wBDdJ4++AFBVB5J8FXimtftKVR1o618CvgPMB37UFknSFEn3AZ6Zp9Pp1ODg4HQPQ5JmlCTbq6ozuu43kCVJhoEkyTCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAk0WcYJFmQZHOSXyR5MckfJ/lykn1Jdrblmp72G5IMJdmdZEVPfWWrDSW5tae+JMlTSfYkeTDJvJN7mpKkY+n3ncFfAY9X1ceATwAvtvpdVbW8LY8BJLkYWAt8HFgJfCPJnCRzgK8Dq4CLgetaW4A72rGWAm8DN5yEc5Mk9WnCMEjyIeDTwH0AVfVuVR08RpfVwKaqeqeqXgaGgMvbMlRVL1XVu8AmYHWSAFcCm1v/jcCa4z0hSdLk9fPO4A+BYeDbSXYk+VaSs9q+m5I8m+T+JAtbbRHwWk//va12tPo5wMGqOjyqPkaS9UkGkwwODw/3c36SpD70EwZzgUuBe6rqEuAfgVuBe4CPAsuB14GvtfYZ5xh1HPWxxap7q6pTVZ2BgYE+hi5J6kc/YbAX2FtVT7XtzcClVfVGVR2pqt8B36Q7DTTS/sKe/ouB/ceovwUsSDJ3VF2SNEUmDIOq+nvgtSTLWukq4IUk5/c0+xzwfFvfAqxNcmaSJcBS4GngGWBpe3JoHt0PmbdUVQFPAte2/uuAR0/wvCRJkzB34iYA/Dnw3faP+EvAF4C7kyynO6XzCvBFgKraleQh4AXgMHBjVR0BSHITsBWYA9xfVbva8W8BNiW5HdhB+7BakjQ10v3FfObpdDo1ODg43cOQpBklyfaq6oyu+w1kSZJhIEkyDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEn0GQZJFiTZnOQXSV5M8sdJzk6yLcme9rqwtU2Su5MMJXk2yaU9x1nX2u9Jsq6nflmS51qfu5Pk5J+qJOlo+n1n8FfA41X1MeATwIvArcATVbUUeKJtA6wClrZlPXAPQJKzgduATwKXA7eNBEhrs76n38oTOy1J0mRMGAZJPgR8GrgPoKreraqDwGpgY2u2EVjT1lcDD1TXz4AFSc4HVgDbqupAVb0NbANWtn0fqqqfVlUBD/QcS5I0Bfp5Z/CHwDDw7SQ7knwryVnAeVX1OkB7Pbe1XwS81tN/b6sdq753nPoYSdYnGUwyODw83MfQJUn96CcM5gKXAvdU1SXAP/JPU0LjGW++v46jPrZYdW9VdaqqMzAwcOxRS5L61k8Y7AX2VtVTbXsz3XB4o03x0F7f7Gl/YU//xcD+CeqLx6lLkqbIhGFQVX8PvJZkWStdBbwAbAFGnghaBzza1rcA17eniq4Aft2mkbYCVydZ2D44vhrY2vb9JskV7Smi63uOJUmaAnP7bPfnwHeTzANeAr5AN0geSnID8Crw+db2MeAaYAj4bWtLVR1I8lXgmdbuK1V1oK1/CfgOMB/4UVskSVMk3Qd4Zp5Op1ODg4PTPQxJmlGSbK+qzui630CWJBkGkiTDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkkSfYZDklSTPJdmZZLDVvpxkX6vtTHJNT/sNSYaS7E6yoqe+stWGktzaU1+S5Kkke5I8mGTeyTxJSdKxTeadwWeqavmoP6R8V6str6rHAJJcDKwFPg6sBL6RZE6SOcDXgVXAxcB1rS3AHe1YS4G3gRtO7LQkSZNxKqaJVgObquqdqnoZGAIub8tQVb1UVe8Cm4DVSQJcCWxu/TcCa07BuCRJR9FvGBTw4yTbk6zvqd+U5Nkk9ydZ2GqLgNd62uxttaPVzwEOVtXhUfUxkqxPMphkcHh4uM+hS5Im0m8YfKqqLqU7xXNjkk8D9wAfBZYDrwNfa20zTv86jvrYYtW9VdWpqs7AwECfQ5ckTaSvMKiq/e31TeAR4PKqeqOqjlTV74Bv0p0Ggu5v9hf2dF8M7D9G/S1gQZK5o+qSpCkyYRgkOSvJB0fWgauB55Oc39Psc8DzbX0LsDbJmUmWAEuBp4FngKXtyaF5dD9k3lJVBTwJXNv6rwMePfFTkyT1a+7ETTgPeKT7OS9zge9V1eNJ/jrJcrpTOq8AXwSoql1JHgJeAA4DN1bVEYAkNwFbgTnA/VW1q/2MW4BNSW4HdgD3naTzkyT1Id1fzGeeTqdTg4OD0z0MSZpRkmwf9RUBwG8gS5IwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIk+gyDJK8keS7JziSDrXZ2km1J9rTXha2eJHcnGUrybJJLe46zrrXfk2RdT/2ydvyh1jcn+0QlSUc3mXcGn6mq5T1/SPlW4ImqWgo80bYBVgFL27IeuAe64QHcBnwSuBy4bSRAWpv1Pf1WHvcZSZIm7USmiVYDG9v6RmBNT/2B6voZsCDJ+cAKYFtVHaiqt4FtwMq270NV9dOqKuCBnmNJkqZAv2FQwI+TbE+yvtXOq6rXAdrrua2+CHitp+/eVjtWfe84dUnSFJnbZ7tPVdX+JOcC25L84hhtx5vvr+Oojz1wN4jWA3zkIx859oglSX3r651BVe1vr28Cj9Cd83+jTfHQXt9szfcCF/Z0Xwzsn6C+eJz6eOO4t6o6VdUZGBjoZ+iSpD5MGAZJzkrywZF14GrgeWALMPJE0Drg0ba+Bbi+PVV0BfDrNo20Fbg6ycL2wfHVwNa27zdJrmhPEV3fcyxJ0hToZ5roPOCR9rTnXOB7VfV4kmeAh5LcALwKfL61fwy4BhgCfgt8AaCqDiT5KvBMa/eVqjrQ1r8EfAeYD/yoLZKkKZLuAzwzT6fTqcHBwekehiTNKEm293xF4Pf8BrIkyTCQJBkGkiT6/57B+8IPduzjzq272X/wEBcsmM/NK5ax5hK/3yZJsyYMfrBjHxsefo5D7x0BYN/BQ2x4+DkAA0HSrDdrponu3Lr790Ew4tB7R7hz6+5pGpEknT5mTRjsP3hoUnVJmk1mTRhcsGD+pOqSNJvMmjC4ecUy5p8x55/V5p8xh5tXLJumEUnS6WPWfIA88iGxTxNJ0lizJgygGwj+4y9JY82aaSJJ0tEZBpIkw0CSZBhIkjAMJEnM4D9uk2QY+NV0j+MU+TDw1nQP4jTgdejyOnR5HbpO9Dr8q6oa80fkZ2wYvJ8lGRzvLxHNNl6HLq9Dl9eh61RdB6eJJEmGgSTJMDhd3TvdAzhNeB26vA5dXoeuU3Id/MxAkuQ7A0mSYSBJwjCYVkn+IMnTSf5vkl1J/nurL0nyVJI9SR5MMm+6x3oqHeM6fCfJy0l2tmX5dI91KiSZk2RHkh+27Vl1P4wY5zrM1vvhlSTPtXMebLWzk2xr98S2JAtP9OcYBtPrHeDKqvoEsBxYmeQK4A7grqpaCrwN3DCNY5wKR7sOADdX1fK27Jy+IU6p/wK82LM92+6HEaOvA8zO+wHgM+2cR75fcCvwRLsnnmjbJ8QwmEbV9f/a5hltKeBKYHOrbwTWTMPwpswxrsOsk2Qx8O+Bb7XtMMvuBxh7HTTGarr3Apyke8IwmGbtrfBO4E1gG/BL4GBVHW5N9gLv+7/IM/o6VNVTbdf/SPJskruSnDmNQ5wqfwn8N+B3bfscZuH9wNjrMGK23Q/Q/cXox0m2J1nfaudV1esA7fXcE/0hhsE0q6ojVbUcWAxcDvyb8ZpN7aim3ujrkOSPgA3Ax4B/C5wN3DKNQzzlkvwH4M2q2t5bHqfp+/p+OMp1gFl2P/T4VFVdCqwCbkzy6VPxQwyD00RVHQT+DrgCWJBk5E+SLgb2T9e4plrPdVhZVa+3KaR3gG/TDcv3s08Bn03yCrCJ7vTQXzL77ocx1yHJ38zC+wGAqtrfXt8EHqF73m8kOR+gvb55oj/HMJhGSQaSLGjr84E/ofuB2ZPAta3ZOuDR6Rnh1DjKdfhFz80eunOiz0/fKE+9qtpQVYur6iJgLfCTqvozZtn9cJTr8B9n2/0AkOSsJB8cWQeupnveW+jeC3CS7om5EzfRKXQ+sDHJHLrB/FBV/TDJC8CmJLcDO4D7pnOQU+Bo1+EnSQboTpXsBP7TdA5yGt3C7Lofjua7s/B+OA94pJt/zAW+V1WPJ3kGeCjJDcCrwOdP9Af531FIkpwmkiQZBpIkDANJEoaBJAnDQJKEYSBJwjCQJAH/H526mFjjaCniAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(data1['Age'], data1['Salary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>France</td>\n",
       "      <td>44.0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Spain</td>\n",
       "      <td>27.0</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Germany</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Spain</td>\n",
       "      <td>38.0</td>\n",
       "      <td>61000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Germany</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>France</td>\n",
       "      <td>35.0</td>\n",
       "      <td>58000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Spain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>France</td>\n",
       "      <td>48.0</td>\n",
       "      <td>79000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Germany</td>\n",
       "      <td>50.0</td>\n",
       "      <td>83000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>France</td>\n",
       "      <td>37.0</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country   Age   Salary Purchased\n",
       "0   France  44.0  72000.0        No\n",
       "1    Spain  27.0  48000.0       Yes\n",
       "2  Germany  30.0  54000.0        No\n",
       "3    Spain  38.0  61000.0        No\n",
       "4  Germany  40.0      NaN       Yes\n",
       "5   France  35.0  58000.0       Yes\n",
       "6    Spain   NaN  52000.0        No\n",
       "7   France  48.0  79000.0       Yes\n",
       "8  Germany  50.0  83000.0        No\n",
       "9   France  37.0  67000.0       Yes"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>38.777778</td>\n",
       "      <td>63777.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>7.693793</td>\n",
       "      <td>12265.579662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>48000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>54000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>61000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>72000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>83000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Age        Salary\n",
       "count   9.000000      9.000000\n",
       "mean   38.777778  63777.777778\n",
       "std     7.693793  12265.579662\n",
       "min    27.000000  48000.000000\n",
       "25%    35.000000  54000.000000\n",
       "50%    38.000000  61000.000000\n",
       "75%    44.000000  72000.000000\n",
       "max    50.000000  83000.000000"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n",
       "        4.00000000e+01, 6.37777778e+04],\n",
       "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        3.70000000e+01, 6.70000000e+04],\n",
       "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        2.70000000e+01, 4.80000000e+04],\n",
       "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        3.87777778e+01, 5.20000000e+04],\n",
       "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        4.80000000e+01, 7.90000000e+04],\n",
       "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        3.80000000e+01, 6.10000000e+04],\n",
       "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        4.40000000e+01, 7.20000000e+04],\n",
       "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        3.50000000e+01, 5.80000000e+04]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "sc_X = StandardScaler()\n",
    "nz_x = Normalizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on StandardScaler in module sklearn.preprocessing.data object:\n",
      "\n",
      "class StandardScaler(sklearn.base.BaseEstimator, sklearn.base.TransformerMixin)\n",
      " |  StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      " |  \n",
      " |  Standardize features by removing the mean and scaling to unit variance\n",
      " |  \n",
      " |  The standard score of a sample `x` is calculated as:\n",
      " |  \n",
      " |      z = (x - u) / s\n",
      " |  \n",
      " |  where `u` is the mean of the training samples or zero if `with_mean=False`,\n",
      " |  and `s` is the standard deviation of the training samples or one if\n",
      " |  `with_std=False`.\n",
      " |  \n",
      " |  Centering and scaling happen independently on each feature by computing\n",
      " |  the relevant statistics on the samples in the training set. Mean and\n",
      " |  standard deviation are then stored to be used on later data using the\n",
      " |  `transform` method.\n",
      " |  \n",
      " |  Standardization of a dataset is a common requirement for many\n",
      " |  machine learning estimators: they might behave badly if the\n",
      " |  individual features do not more or less look like standard normally\n",
      " |  distributed data (e.g. Gaussian with 0 mean and unit variance).\n",
      " |  \n",
      " |  For instance many elements used in the objective function of\n",
      " |  a learning algorithm (such as the RBF kernel of Support Vector\n",
      " |  Machines or the L1 and L2 regularizers of linear models) assume that\n",
      " |  all features are centered around 0 and have variance in the same\n",
      " |  order. If a feature has a variance that is orders of magnitude larger\n",
      " |  that others, it might dominate the objective function and make the\n",
      " |  estimator unable to learn from other features correctly as expected.\n",
      " |  \n",
      " |  This scaler can also be applied to sparse CSR or CSC matrices by passing\n",
      " |  `with_mean=False` to avoid breaking the sparsity structure of the data.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <preprocessing_scaler>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  copy : boolean, optional, default True\n",
      " |      If False, try to avoid a copy and do inplace scaling instead.\n",
      " |      This is not guaranteed to always work inplace; e.g. if the data is\n",
      " |      not a NumPy array or scipy.sparse CSR matrix, a copy may still be\n",
      " |      returned.\n",
      " |  \n",
      " |  with_mean : boolean, True by default\n",
      " |      If True, center the data before scaling.\n",
      " |      This does not work (and will raise an exception) when attempted on\n",
      " |      sparse matrices, because centering them entails building a dense\n",
      " |      matrix which in common use cases is likely to be too large to fit in\n",
      " |      memory.\n",
      " |  \n",
      " |  with_std : boolean, True by default\n",
      " |      If True, scale the data to unit variance (or equivalently,\n",
      " |      unit standard deviation).\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  scale_ : ndarray or None, shape (n_features,)\n",
      " |      Per feature relative scaling of the data. This is calculated using\n",
      " |      `np.sqrt(var_)`. Equal to ``None`` when ``with_std=False``.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *scale_*\n",
      " |  \n",
      " |  mean_ : ndarray or None, shape (n_features,)\n",
      " |      The mean value for each feature in the training set.\n",
      " |      Equal to ``None`` when ``with_mean=False``.\n",
      " |  \n",
      " |  var_ : ndarray or None, shape (n_features,)\n",
      " |      The variance for each feature in the training set. Used to compute\n",
      " |      `scale_`. Equal to ``None`` when ``with_std=False``.\n",
      " |  \n",
      " |  n_samples_seen_ : int or array, shape (n_features,)\n",
      " |      The number of samples processed by the estimator for each feature.\n",
      " |      If there are not missing samples, the ``n_samples_seen`` will be an\n",
      " |      integer, otherwise it will be an array.\n",
      " |      Will be reset on new calls to fit, but increments across\n",
      " |      ``partial_fit`` calls.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.preprocessing import StandardScaler\n",
      " |  >>> data = [[0, 0], [0, 0], [1, 1], [1, 1]]\n",
      " |  >>> scaler = StandardScaler()\n",
      " |  >>> print(scaler.fit(data))\n",
      " |  StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      " |  >>> print(scaler.mean_)\n",
      " |  [0.5 0.5]\n",
      " |  >>> print(scaler.transform(data))\n",
      " |  [[-1. -1.]\n",
      " |   [-1. -1.]\n",
      " |   [ 1.  1.]\n",
      " |   [ 1.  1.]]\n",
      " |  >>> print(scaler.transform([[2, 2]]))\n",
      " |  [[3. 3.]]\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  scale: Equivalent function without the estimator API.\n",
      " |  \n",
      " |  :class:`sklearn.decomposition.PCA`\n",
      " |      Further removes the linear correlation across features with 'whiten=True'.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  NaNs are treated as missing values: disregarded in fit, and maintained in\n",
      " |  transform.\n",
      " |  \n",
      " |  We use a biased estimator for the standard deviation, equivalent to\n",
      " |  `numpy.std(x, ddof=0)`. Note that the choice of `ddof` is unlikely to\n",
      " |  affect model performance.\n",
      " |  \n",
      " |  For a comparison of the different scalers, transformers, and normalizers,\n",
      " |  see :ref:`examples/preprocessing/plot_all_scaling.py\n",
      " |  <sphx_glr_auto_examples_preprocessing_plot_all_scaling.py>`.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      StandardScaler\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.TransformerMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, copy=True, with_mean=True, with_std=True)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y=None)\n",
      " |      Compute the mean and std to be used for later scaling.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape [n_samples, n_features]\n",
      " |          The data used to compute the mean and standard deviation\n",
      " |          used for later scaling along the features axis.\n",
      " |      \n",
      " |      y\n",
      " |          Ignored\n",
      " |  \n",
      " |  inverse_transform(self, X, copy=None)\n",
      " |      Scale back the data to the original representation\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape [n_samples, n_features]\n",
      " |          The data used to scale along the features axis.\n",
      " |      copy : bool, optional (default: None)\n",
      " |          Copy the input X or not.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_tr : array-like, shape [n_samples, n_features]\n",
      " |          Transformed array.\n",
      " |  \n",
      " |  partial_fit(self, X, y=None)\n",
      " |      Online computation of mean and std on X for later scaling.\n",
      " |      All of X is processed as a single batch. This is intended for cases\n",
      " |      when `fit` is not feasible due to very large number of `n_samples`\n",
      " |      or because X is read from a continuous stream.\n",
      " |      \n",
      " |      The algorithm for incremental mean and std is given in Equation 1.5a,b\n",
      " |      in Chan, Tony F., Gene H. Golub, and Randall J. LeVeque. \"Algorithms\n",
      " |      for computing the sample variance: Analysis and recommendations.\"\n",
      " |      The American Statistician 37.3 (1983): 242-247:\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape [n_samples, n_features]\n",
      " |          The data used to compute the mean and standard deviation\n",
      " |          used for later scaling along the features axis.\n",
      " |      \n",
      " |      y\n",
      " |          Ignored\n",
      " |  \n",
      " |  transform(self, X, copy=None)\n",
      " |      Perform standardization by centering and scaling\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape [n_samples, n_features]\n",
      " |          The data used to scale along the features axis.\n",
      " |      copy : bool, optional (default: None)\n",
      " |          Copy the input X or not.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.TransformerMixin:\n",
      " |  \n",
      " |  fit_transform(self, X, y=None, **fit_params)\n",
      " |      Fit to data, then transform it.\n",
      " |      \n",
      " |      Fits transformer to X and y with optional parameters fit_params\n",
      " |      and returns a transformed version of X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : numpy array of shape [n_samples, n_features]\n",
      " |          Training set.\n",
      " |      \n",
      " |      y : numpy array of shape [n_samples]\n",
      " |          Target values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_new : numpy array of shape [n_samples, n_features_new]\n",
      " |          Transformed array.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(sc_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Normalizer in module sklearn.preprocessing.data object:\n",
      "\n",
      "class Normalizer(sklearn.base.BaseEstimator, sklearn.base.TransformerMixin)\n",
      " |  Normalizer(norm='l2', copy=True)\n",
      " |  \n",
      " |  Normalize samples individually to unit norm.\n",
      " |  \n",
      " |  Each sample (i.e. each row of the data matrix) with at least one\n",
      " |  non zero component is rescaled independently of other samples so\n",
      " |  that its norm (l1 or l2) equals one.\n",
      " |  \n",
      " |  This transformer is able to work both with dense numpy arrays and\n",
      " |  scipy.sparse matrix (use CSR format if you want to avoid the burden of\n",
      " |  a copy / conversion).\n",
      " |  \n",
      " |  Scaling inputs to unit norms is a common operation for text\n",
      " |  classification or clustering for instance. For instance the dot\n",
      " |  product of two l2-normalized TF-IDF vectors is the cosine similarity\n",
      " |  of the vectors and is the base similarity metric for the Vector\n",
      " |  Space Model commonly used by the Information Retrieval community.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <preprocessing_normalization>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  norm : 'l1', 'l2', or 'max', optional ('l2' by default)\n",
      " |      The norm to use to normalize each non zero sample.\n",
      " |  \n",
      " |  copy : boolean, optional, default True\n",
      " |      set to False to perform inplace row normalization and avoid a\n",
      " |      copy (if the input is already a numpy array or a scipy.sparse\n",
      " |      CSR matrix).\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.preprocessing import Normalizer\n",
      " |  >>> X = [[4, 1, 2, 2],\n",
      " |  ...      [1, 3, 9, 3],\n",
      " |  ...      [5, 7, 5, 1]]\n",
      " |  >>> transformer = Normalizer().fit(X)  # fit does nothing.\n",
      " |  >>> transformer\n",
      " |  Normalizer(copy=True, norm='l2')\n",
      " |  >>> transformer.transform(X)\n",
      " |  array([[0.8, 0.2, 0.4, 0.4],\n",
      " |         [0.1, 0.3, 0.9, 0.3],\n",
      " |         [0.5, 0.7, 0.5, 0.1]])\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  This estimator is stateless (besides constructor parameters), the\n",
      " |  fit method does nothing but is useful when used in a pipeline.\n",
      " |  \n",
      " |  For a comparison of the different scalers, transformers, and normalizers,\n",
      " |  see :ref:`examples/preprocessing/plot_all_scaling.py\n",
      " |  <sphx_glr_auto_examples_preprocessing_plot_all_scaling.py>`.\n",
      " |  \n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  normalize: Equivalent function without the estimator API.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Normalizer\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.TransformerMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, norm='l2', copy=True)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y=None)\n",
      " |      Do nothing and return the estimator unchanged\n",
      " |      \n",
      " |      This method is just there to implement the usual API and hence\n",
      " |      work in pipelines.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like\n",
      " |  \n",
      " |  transform(self, X, copy=None)\n",
      " |      Scale each non zero row of X to unit norm\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape [n_samples, n_features]\n",
      " |          The data to normalize, row by row. scipy.sparse matrices should be\n",
      " |          in CSR format to avoid an un-necessary copy.\n",
      " |      copy : bool, optional (default: None)\n",
      " |          Copy the input X or not.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.TransformerMixin:\n",
      " |  \n",
      " |  fit_transform(self, X, y=None, **fit_params)\n",
      " |      Fit to data, then transform it.\n",
      " |      \n",
      " |      Fits transformer to X and y with optional parameters fit_params\n",
      " |      and returns a transformed version of X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : numpy array of shape [n_samples, n_features]\n",
      " |          Training set.\n",
      " |      \n",
      " |      y : numpy array of shape [n_samples]\n",
      " |          Target values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_new : numpy array of shape [n_samples, n_features_new]\n",
      " |          Transformed array.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(nz_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -1.        ,  2.64575131, -0.77459667,  0.26306757,\n",
       "         0.12381479],\n",
       "       [-1.        ,  1.        , -0.37796447, -0.77459667, -0.25350148,\n",
       "         0.46175632],\n",
       "       [ 1.        , -1.        , -0.37796447,  1.29099445, -1.97539832,\n",
       "        -1.53093341],\n",
       "       [ 1.        , -1.        , -0.37796447,  1.29099445,  0.05261351,\n",
       "        -1.11141978],\n",
       "       [-1.        ,  1.        , -0.37796447, -0.77459667,  1.64058505,\n",
       "         1.7202972 ],\n",
       "       [ 1.        , -1.        , -0.37796447,  1.29099445, -0.0813118 ,\n",
       "        -0.16751412],\n",
       "       [-1.        ,  1.        , -0.37796447, -0.77459667,  0.95182631,\n",
       "         0.98614835],\n",
       "       [-1.        ,  1.        , -0.37796447, -0.77459667, -0.59788085,\n",
       "        -0.48214934]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_Standard = sc_X.fit_transform(X_train)\n",
    "X_test_Standard = sc_X.fit(X_test)\n",
    "X_train_Standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.56794394e-05, 0.00000000e+00, 1.56794394e-05, 0.00000000e+00,\n",
       "        6.27177577e-04, 9.99999803e-01],\n",
       "       [0.00000000e+00, 1.49253709e-05, 0.00000000e+00, 0.00000000e+00,\n",
       "        5.52238722e-04, 9.99999847e-01],\n",
       "       [2.08333300e-05, 0.00000000e+00, 0.00000000e+00, 2.08333300e-05,\n",
       "        5.62499911e-04, 9.99999841e-01],\n",
       "       [1.92307639e-05, 0.00000000e+00, 0.00000000e+00, 1.92307639e-05,\n",
       "        7.45726288e-04, 9.99999722e-01],\n",
       "       [0.00000000e+00, 1.26582255e-05, 0.00000000e+00, 0.00000000e+00,\n",
       "        6.07594825e-04, 9.99999815e-01],\n",
       "       [1.63934394e-05, 0.00000000e+00, 0.00000000e+00, 1.63934394e-05,\n",
       "        6.22950699e-04, 9.99999806e-01],\n",
       "       [0.00000000e+00, 1.38888863e-05, 0.00000000e+00, 0.00000000e+00,\n",
       "        6.11110997e-04, 9.99999813e-01],\n",
       "       [0.00000000e+00, 1.72413762e-05, 0.00000000e+00, 0.00000000e+00,\n",
       "        6.03448166e-04, 9.99999818e-01]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_Normalized = nz_x.fit_transform(X_train)\n",
    "X_test_Normalized = nz_x.fit(X_test)\n",
    "X_train_Normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
